{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "\n",
    "def get_system_usage():\n",
    "    process = psutil.Process()\n",
    "    cpu_usage = process.cpu_percent(interval=1)\n",
    "    memory_info = process.memory_info()\n",
    "    memory_usage = memory_info.rss / (1024 ** 2)\n",
    "    return cpu_usage, memory_usage\n",
    "\n",
    "# Tiempo\n",
    "start_time = time.time()\n",
    "start_cpu_usage, start_memory_usage = get_system_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/djcatalan/Documents/BIRADS/RAG\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!xdg-open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BAAI/bge-small-en. Creating a new one with MEAN pooling.\n",
      "/data/home/djcatalan/.conda/envs/new_djcatalan/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 259\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3904\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   488.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  488.00 MiB, K (f16):  244.00 MiB, V (f16):  244.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   283.63 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.core.indices.service_context import ServiceContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "cache_folder = \"./model_cache\"\n",
    "#embed_model = HuggingFaceEmbedding(\n",
    "#    model_name=\"BAAI/bge-small-en\", cache_folder = cache_folder)\n",
    "embed_model = resolve_embed_model(\"local:BAAI/bge-small-en\")\n",
    "#llm = 'local:mistral-7b-instruct-v0.1.Q4_K_M.gguf'\n",
    "#llm = 'local:mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf'\n",
    "#llm = 'local:gemma-7b-it.fp16.gguf'\n",
    "\n",
    "llm='local:mistral-7b-instruct-v0.1.Q4_K_M.gguf'\n",
    "Settings.llm=llm\n",
    "Settings.embed_model=embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Directorio\n",
    "path= \"/data/home/djcatalan/Documents/BIRADS/RAG/Mamografies.csv\"\n",
    "\n",
    "# Leer .csv\n",
    "df = pd.read_csv(path, encoding='ISO-8859-1', delimiter=';')\n",
    "\n",
    "# Normalizar texto html\n",
    "df['Contingut'] = df['Contingut'].apply(lambda x: BeautifulSoup(str(x).lower(), \"html.parser\").get_text() if isinstance(x, str) and '<' in x and '>' in x else x)\n",
    "\n",
    "# Normalizar prueba diagnostica\n",
    "df['Prova'] = df['Prova'].apply(lambda x: re.sub(r'\\d+\\.?', '', str(x)).replace('[', '').replace(']', '').strip().lower() if isinstance(x, str) else str(x).lower())\n",
    "\n",
    "# Eliminar datos personales\n",
    "def remove_data(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub('barcelona.*', 'barcelona', text)\n",
    "    return text\n",
    "\n",
    "df['Contingut']=df['Contingut'].apply(remove_data)\n",
    "\n",
    "# Columnas son numéricas\n",
    "df['Historia'] = pd.to_numeric(df['Historia'], errors='coerce')\n",
    "df['Exploracio'] = pd.to_numeric(df['Exploracio'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes: 18708\n",
      "Después: 17164\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay duplicados\n",
    "duplicados = df.duplicated(subset=[\"Historia\", \"Exploracio\"], keep=False)\n",
    "\n",
    "# Eliminar duplicados\n",
    "df_dedup = df.drop_duplicates(subset=[\"Historia\", \"Exploracio\"])\n",
    "\n",
    "# Comparar tamaños antes y después\n",
    "df_before = len(df)\n",
    "df_after = len(df_dedup)\n",
    "\n",
    "print(f'Antes: {df_before}')\n",
    "print(f'Después: {df_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Exploracio   Historia        Data       Prova  \\\n",
      "0     3721809   109368.0  03/01/2018  mamografia   \n",
      "1     3540069   193146.0  03/01/2018  mamografia   \n",
      "2     3543745  1538814.0  03/01/2018  mamografia   \n",
      "3     3540030   213314.0  03/01/2018  mamografia   \n",
      "4     3537201  1250727.0  03/01/2018  mamografia   \n",
      "\n",
      "                                           Contingut  \n",
      "0   mamografía.motivo de exploración: control gin...  \n",
      "1  mamografía.motivo de exploración: control onco...  \n",
      "2  ecografía + mamografía bilateralmotivo de soli...  \n",
      "3  mamografía.motivo de exploración: control onco...  \n",
      "4   mamografía.motivo de exploración: control onc...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 17164\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "if not isinstance(df_dedup, pd.DataFrame):\n",
    "    raise ValueError (\"no Dataframe\")\n",
    "\n",
    "# Crear Document\n",
    "documents = []\n",
    "\n",
    "for idx, row in df_dedup.iterrows():\n",
    "    document_id = row[\"Exploracio\"]\n",
    "\n",
    "    metadata = {\n",
    "        \"Numero exploracion\": row[\"Exploracio\"],\n",
    "        \"Numero historia\": row[\"Historia\"],\n",
    "        \"Fecha de consulta\": row[\"Data\"],\n",
    "        \"Prueba diagnostica\": row[\"Prova\"],\n",
    "    }\n",
    "    document = Document(\n",
    "        text=row[\"Contingut\"],\n",
    "        id_=document_id,\n",
    "        metadata=metadata,\n",
    "        excluded_llm_metadata_keys=['file_path', 'file_type', 'file_size', 'creation_date', 'last_modified_date'],\n",
    "        metadata_separator=\"::\",\n",
    "        metadata_template=\"{key}=>{value}\",\n",
    "        text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n",
    "    )\n",
    "    \n",
    "    documents.append(document)\n",
    "\n",
    "print(f\"Total: {len(documents)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 ID: 3721809\n",
      "The LLM see this: \n",
      " Metadata: Numero exploracion=>3721809\n",
      "Numero historia=>109368.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "-----\n",
      "Content:  mamografía.motivo de exploración: control ginecológico.resultados:mamas simétricas con predominio del tejido graso.no se observan lesiones focales sospechosas. conclusión: negativo. birads 1.densidad mamaria: a.\n",
      "Document 1 ID: 3540069\n",
      "The LLM see this: \n",
      " Metadata: Numero exploracion=>3540069\n",
      "Numero historia=>193146.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "-----\n",
      "Content: mamografía.motivo de exploración: control oncológico. antecedente de tumorectomía bilateral.resultados:mamas con tejido fibroepitelial denso de forma heterogénea. se observan cambios secundarios a tratamiento quirúrgico conservador y radioterapia de ambas mamas. la cicatriz de mi es un tanto densa, pero sin cambios significativos respecto a controles previos y en la cicatriz de md se observan calcificaciones de liponecrosis.proyectado sobre prolongación axilar izqueirda, a 12cm del pezón, se observa un nodulillo de bordes poco nítidos y 3mm de diámetro que parece ser de reciente aparición.no se observan lesiones focales sospechosas. conclusión: imagen en mi que requiere estudio complementario. birads 0. se programará mamografía con contraste y ecografía complementarias para su estudio más detallado.densidad mamaria: c.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(documents[:2]):\n",
    "    print(f\"Document {i} ID: {doc.id_}\")\n",
    "    print(\"The LLM see this: \\n\", doc.get_content(metadata_mode=MetadataMode.LLM))\n",
    "    #print(\"The embedding model see this: \\n\", doc.get_content(metadata_mode=MetadataMode.EMBED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir apartados\n",
    "def extract_conclusion(text):\n",
    "    conclusion_pattern = r'\\b(?:conclusi[óo]ne?s?|impresi[óo]ne?s?(\\s+diagn[oó]stica)?)\\s*:\\s*(.*)'\n",
    "    match = re.search(conclusion_pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(2).strip()\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conclusiones duplicadas y su conteo:\n",
      "Conclusion\n",
      "                                                                                                                                                                                              2115\n",
      "negativo. birads 1.densidad mamaria: b.                                                                                                                                                        543\n",
      "negativo. birads 1.densidad mamaria: c.                                                                                                                                                        449\n",
      "lesiones benignas. birads 2.densidad mamaria: b.                                                                                                                                               280\n",
      "lesiones benignas. birads 2.densidad mamaria: c.                                                                                                                                               240\n",
      "                                                                                                                                                                                              ... \n",
      "negativo. birads 1. controles habituales.densidad mamaria:b.                                                                                                                                     2\n",
      "cambios secundarios a tratamiento conservador md. birads 2. controles periodicos.densidad: b.cambios secundarios a tratamiento conservador md. birads 2. controles periodicos.densidad: b.       2\n",
      "negativo. birads 1.densidad mamaria c. controles clínicos ginecológicos                                                                                                                          2\n",
      "birads 1 estudio dentro de la normalidad. se recomiendan controles periódicos habituales.densidad mamaria: b.                                                                                    2\n",
      "birads 1 hallazgos dentro de la normalidad. densidad b. se recomiendan controles periódicos habituales.                                                                                          2\n",
      "Name: count, Length: 1063, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Función para limpiar el texto de caracteres especiales\n",
    "def clean_text(text):\n",
    "    # Definir la expresión regular para permitir letras, números, espacios, puntuación y tildes\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,;:!?áéíóúÁÉÍÓÚñÑ]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Definir función para extraer conclusiones\n",
    "def extract_conclusion(text):\n",
    "    text = clean_text(text)  # Limpiar el texto antes de extraer la conclusión\n",
    "    conclusion_pattern = r'\\b(?:conclusi[oó]ne?s?|impresi[oó]ne?s?(\\s+diagn[oó]stica)?)\\s*:\\s*(.*)'\n",
    "    match = re.search(conclusion_pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(2).strip()\n",
    "    return \"\"\n",
    "\n",
    "# Extraer conclusiones y almacenar en una lista\n",
    "conclusions = [extract_conclusion(doc.text) for doc in documents]\n",
    "\n",
    "# Crear un DataFrame a partir de las conclusiones\n",
    "df_conclusions = pd.DataFrame(conclusions, columns=['Conclusion'])\n",
    "\n",
    "# Verificar y contar los duplicados\n",
    "duplicated_conclusions = df_conclusions.duplicated(keep=False)\n",
    "duplicated_df = df_conclusions[duplicated_conclusions]\n",
    "duplicated_count = duplicated_df['Conclusion'].value_counts()\n",
    "\n",
    "print(\"Conclusiones duplicadas y su conteo:\")\n",
    "print(duplicated_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de conclusiones antes de eliminar duplicados: 17164\n",
      "Total de conclusiones después de eliminar duplicados: 7296\n"
     ]
    }
   ],
   "source": [
    "# Eliminar duplicados\n",
    "df_conclusions_unique = df_conclusions.drop_duplicates()\n",
    "\n",
    "# Contar conclusiones antes y después de eliminar duplicados\n",
    "conclusions_before = len(df_conclusions)\n",
    "conclusions_after = len(df_conclusions_unique)\n",
    "\n",
    "print(f\"Total de conclusiones antes de eliminar duplicados: {conclusions_before}\")\n",
    "print(f\"Total de conclusiones después de eliminar duplicados: {conclusions_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraccion de BIRADS en Conclusion\n",
    "def extract_bi_rads(text):\n",
    "    bi_rads_matches = re.findall(r'bi\\s*-?\\s*rads\\s*:? ?(4\\s*[a-c]?|6|5|3|2|1|0)', text)\n",
    "    if not bi_rads_matches:\n",
    "        return 'no especifica BIRADS en el documento'\n",
    "    \n",
    "    bi_rads_norm = set()\n",
    "    for match in bi_rads_matches:\n",
    "        match = match.replace(\" \",\"\")\n",
    "        if match.startswith('4'):\n",
    "            if len(match) > 1:\n",
    "                match = '4' + match[1].lower()\n",
    "        bi_rads_norm.add(match)\n",
    "    bi_rads = \", \".join(f\"BIRADS {item}\" for item in sorted(bi_rads_norm)) # Concatena\n",
    "    return bi_rads\n",
    "\n",
    "# Extraer lateralidad en Conclusion\n",
    "def extract_lateralidad(text):\n",
    "    lateralidad_matches = r'\\b(derecha|izquierda|esquerra|dreta|md|mi)\\b'\n",
    "    matches = re.findall(lateralidad_matches, text)\n",
    "    if not matches:\n",
    "        return \"no especifica lateralidad de la mama\"\n",
    "    \n",
    "    lateralidad_norm = set()\n",
    "    for match in matches:\n",
    "        if match in ['derecha', 'dreta', 'md']:\n",
    "            lateralidad_norm.add('mama derecha')\n",
    "            text = re.sub(r'\\b' + re.escape(match) + r'\\b', \"mama derecha\", text)\n",
    "        elif match in ['izquierda', 'esquerra', 'mi']:\n",
    "            lateralidad_norm.add('mama izquierda')\n",
    "            text = re.sub(r'\\b' + re.escape(match) + r'\\b', \"mama izquierda\", text)\n",
    "        \n",
    "    return \", \".join(sorted(lateralidad_norm)) if lateralidad_norm else \"no especifica lateralidad de la mama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar funciones extract_bi_rads y extract_lateralidad a las conclusiones únicas\n",
    "bi_rads_results = df_conclusions_unique['Conclusion'].apply(extract_bi_rads)\n",
    "lateralidad_results = df_conclusions_unique['Conclusion'].apply(extract_lateralidad)\n",
    "\n",
    "# Crear un diccionario para mapear conclusiones a los resultados de las funciones\n",
    "bi_rads_dict = dict(zip(df_conclusions_unique['Conclusion'], bi_rads_results))\n",
    "lateralidad_dict = dict(zip(df_conclusions_unique['Conclusion'], lateralidad_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLM see this: \n",
      " Metadata: Numero exploracion=>3721809\n",
      "Numero historia=>109368.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "BI-RADS=>BIRADS 1\n",
      "Lateralidad mama=>no especifica lateralidad de la mama\n",
      "-----\n",
      "Content:  mamografía.motivo de exploración: control ginecológico.resultados:mamas simétricas con predominio del tejido graso.no se observan lesiones focales sospechosas. conclusión: negativo. birads 1.densidad mamaria: a.\n",
      "The embedding model see this: \n",
      " Metadata: Numero exploracion=>3721809\n",
      "Numero historia=>109368.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "BI-RADS=>BIRADS 1\n",
      "Lateralidad mama=>no especifica lateralidad de la mama\n",
      "-----\n",
      "Content:  mamografía.motivo de exploración: control ginecológico.resultados:mamas simétricas con predominio del tejido graso.no se observan lesiones focales sospechosas. conclusión: negativo. birads 1.densidad mamaria: a.\n",
      "The LLM see this: \n",
      " Metadata: Numero exploracion=>3540069\n",
      "Numero historia=>193146.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "BI-RADS=>BIRADS 0\n",
      "Lateralidad mama=>mama izquierda\n",
      "-----\n",
      "Content: mamografía.motivo de exploración: control oncológico. antecedente de tumorectomía bilateral.resultados:mamas con tejido fibroepitelial denso de forma heterogénea. se observan cambios secundarios a tratamiento quirúrgico conservador y radioterapia de ambas mamas. la cicatriz de mi es un tanto densa, pero sin cambios significativos respecto a controles previos y en la cicatriz de md se observan calcificaciones de liponecrosis.proyectado sobre prolongación axilar izqueirda, a 12cm del pezón, se observa un nodulillo de bordes poco nítidos y 3mm de diámetro que parece ser de reciente aparición.no se observan lesiones focales sospechosas. conclusión: imagen en mi que requiere estudio complementario. birads 0. se programará mamografía con contraste y ecografía complementarias para su estudio más detallado.densidad mamaria: c.\n",
      "The embedding model see this: \n",
      " Metadata: Numero exploracion=>3540069\n",
      "Numero historia=>193146.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "BI-RADS=>BIRADS 0\n",
      "Lateralidad mama=>mama izquierda\n",
      "-----\n",
      "Content: mamografía.motivo de exploración: control oncológico. antecedente de tumorectomía bilateral.resultados:mamas con tejido fibroepitelial denso de forma heterogénea. se observan cambios secundarios a tratamiento quirúrgico conservador y radioterapia de ambas mamas. la cicatriz de mi es un tanto densa, pero sin cambios significativos respecto a controles previos y en la cicatriz de md se observan calcificaciones de liponecrosis.proyectado sobre prolongación axilar izqueirda, a 12cm del pezón, se observa un nodulillo de bordes poco nítidos y 3mm de diámetro que parece ser de reciente aparición.no se observan lesiones focales sospechosas. conclusión: imagen en mi que requiere estudio complementario. birads 0. se programará mamografía con contraste y ecografía complementarias para su estudio más detallado.densidad mamaria: c.\n",
      "The LLM see this: \n",
      " Metadata: Numero exploracion=>3543745\n",
      "Numero historia=>1538814.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "BI-RADS=>BIRADS 2\n",
      "Lateralidad mama=>mama derecha\n",
      "-----\n",
      "Content: ecografía + mamografía bilateralmotivo de solicitud: ca de mama d, tto conservador. control anual.resultados:mamografía: se compara con mx previas del 2012-2016.mamas con predominio del tejido graso.cambios por tratamiento conservador y radioterapia de la md, con presencia de calcificaciones liponecróticas y discreto aumento de densidad en ucs de la md, estables evolutivamente. no se observan focalidades sospechosas.ecografíatejido fibroglandular disperso.cicatriz qx en ucs de la md de aspecto irregular, con centro hipodenso asociado a calcificaciones groseras, sin mostrar vascularización aumentada por estudio doppler color ni dureza aumentada por elastografía.no se identifican lesiones focales sospechosas ni adenopatías axilares.conclusión: cambios por tto conservador md, estables evolutivamente. birads 2. controles periodicos habituales.densidad mamaria:a.\n",
      "The embedding model see this: \n",
      " Metadata: Numero exploracion=>3543745\n",
      "Numero historia=>1538814.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "BI-RADS=>BIRADS 2\n",
      "Lateralidad mama=>mama derecha\n",
      "-----\n",
      "Content: ecografía + mamografía bilateralmotivo de solicitud: ca de mama d, tto conservador. control anual.resultados:mamografía: se compara con mx previas del 2012-2016.mamas con predominio del tejido graso.cambios por tratamiento conservador y radioterapia de la md, con presencia de calcificaciones liponecróticas y discreto aumento de densidad en ucs de la md, estables evolutivamente. no se observan focalidades sospechosas.ecografíatejido fibroglandular disperso.cicatriz qx en ucs de la md de aspecto irregular, con centro hipodenso asociado a calcificaciones groseras, sin mostrar vascularización aumentada por estudio doppler color ni dureza aumentada por elastografía.no se identifican lesiones focales sospechosas ni adenopatías axilares.conclusión: cambios por tto conservador md, estables evolutivamente. birads 2. controles periodicos habituales.densidad mamaria:a.\n",
      "The LLM see this: \n",
      " Metadata: Numero exploracion=>3540030\n",
      "Numero historia=>213314.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "BI-RADS=>BIRADS 2\n",
      "Lateralidad mama=>no especifica lateralidad de la mama\n",
      "-----\n",
      "Content: mamografía.motivo de exploración: control oncológico. antecedente de tumorectomía derecha.resultados:mamas con áreas de tejido fibroepitelial disperso. se observan cambios secundarios a tratamiento quirúrgico conservador y radioterapia de mama derecha.en cse de md se observa una pequeña asimetría focal sin cambios significativos desde 2010.no se observan lesiones focales sospechosas. conclusión: lesiones benignas. birads 2.densidad mamaria: b.\n",
      "The embedding model see this: \n",
      " Metadata: Numero exploracion=>3540030\n",
      "Numero historia=>213314.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "BI-RADS=>BIRADS 2\n",
      "Lateralidad mama=>no especifica lateralidad de la mama\n",
      "-----\n",
      "Content: mamografía.motivo de exploración: control oncológico. antecedente de tumorectomía derecha.resultados:mamas con áreas de tejido fibroepitelial disperso. se observan cambios secundarios a tratamiento quirúrgico conservador y radioterapia de mama derecha.en cse de md se observa una pequeña asimetría focal sin cambios significativos desde 2010.no se observan lesiones focales sospechosas. conclusión: lesiones benignas. birads 2.densidad mamaria: b.\n",
      "The LLM see this: \n",
      " Metadata: Numero exploracion=>3537201\n",
      "Numero historia=>1250727.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "BI-RADS=>BIRADS 2\n",
      "Lateralidad mama=>no especifica lateralidad de la mama\n",
      "-----\n",
      "Content:  mamografía.motivo de exploración: control oncológico. antecedente de tumorectomía bilateral (lesión neoplásica en md y lesión benigna en mi).resultados:mamas con áreas de tejido fibroepitelial disperso. se observan cambios secundarios a tratamiento quirúrgico conservador de ambas mamas. en el lecho quirúgico de md se observa calcificaciones de liponecrosis.no se observan lesiones focales sospechosas. conclusión: imágenes benignas. birads 2.densidad mamaria: b.\n",
      "The embedding model see this: \n",
      " Metadata: Numero exploracion=>3537201\n",
      "Numero historia=>1250727.0\n",
      "Fecha de consulta=>03/01/2018\n",
      "Prueba diagnostica=>mamografia\n",
      "BI-RADS=>BIRADS 2\n",
      "Lateralidad mama=>no especifica lateralidad de la mama\n",
      "-----\n",
      "Content:  mamografía.motivo de exploración: control oncológico. antecedente de tumorectomía bilateral (lesión neoplásica en md y lesión benigna en mi).resultados:mamas con áreas de tejido fibroepitelial disperso. se observan cambios secundarios a tratamiento quirúrgico conservador de ambas mamas. en el lecho quirúgico de md se observa calcificaciones de liponecrosis.no se observan lesiones focales sospechosas. conclusión: imágenes benignas. birads 2.densidad mamaria: b.\n"
     ]
    }
   ],
   "source": [
    "# Actualizar metadatos\n",
    "for doc, conclusion_text in zip(documents, conclusions):\n",
    "    doc.metadata[\"BI-RADS\"] = bi_rads_dict[conclusion_text]\n",
    "    doc.metadata[\"Lateralidad mama\"] = lateralidad_dict[conclusion_text]\n",
    "\n",
    "for doc in documents[:5]:\n",
    "    print(\"The LLM see this: \\n\", doc.get_content(metadata_mode=MetadataMode.LLM))\n",
    "    print(\"The embedding model see this: \\n\", doc.get_content(metadata_mode=MetadataMode.EMBED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "birads_values = [doc.metadata[\"BI-RADS\"] for doc in documents if \"BI-RADS\" in doc.metadata]\n",
    "birads_counts = pd.Series(birads_values).values_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMATION\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from typing import List\n",
    "\n",
    "# Homogenizar BIRADS y Lateralidad\n",
    "def homogenizer(text):\n",
    "    text = re.sub(r'\\bbi\\s*-?\\s*rads\\s*:? ?', 'birads ', text)\n",
    "    text = re.sub(r'\\b4\\s*(a|b|c)\\b', r'4\\1', text)\n",
    "    text = re.sub(r'mama\\s*derecha|mama\\s*dreta|\\bmd\\b', \"mama derecha\", text)\n",
    "    text = re.sub(r'mama\\s*izquierda|mama\\s*esquerra|\\bmi\\b', \"mama izquierda\", text)\n",
    "    return text\n",
    "\n",
    "def clean_puntuation(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def eliminate_tildes(text, remove_tildes= True) -> str:\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    if remove_tildes:\n",
    "        # Reemplazar tildes agudas y graves por vocales base\n",
    "        text = re.sub('[áà]', 'a', text)\n",
    "        text = re.sub('[éè]', 'e', text)\n",
    "        text = re.sub('[íì]', 'i', text)\n",
    "        text = re.sub('[óò]', 'o', text)\n",
    "        text = re.sub('[úù]', 'u', text)\n",
    "    \n",
    "    # Eliminar espacios adicionales\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Splitting y eliminacion de caracteres\n",
    "patterns = {\n",
    "        'Motivo': r'\\b(ecografia|mamografia*motivo|mamografia\\smotivo|mamografias*ecografia|mamografia\\secografia)\\b', \n",
    "        'Resultados': r'\\b(resultado|resultados)\\b', \n",
    "        'Conclusion': r'\\b(conclusion|conclusiones|impresion|impresiones|impresiones+diagnostica)\\b'\n",
    "    }\n",
    "\n",
    "def custom_sentence_splitter(text, chunk_size=None):\n",
    "    sentences = []\n",
    "    combined_pattern = '|'.join(patterns.values())\n",
    "    matches = list(re.finditer(combined_pattern, text))\n",
    "\n",
    "    if not matches:\n",
    "        chunk_size = chunk_size or 500\n",
    "        for i in range(0, len(text), chunk_size):\n",
    "            sentences.append(text[i:i+chunk_size].strip())\n",
    "        return sentences\n",
    "\n",
    "    prev_end = 0\n",
    "    for i, match in enumerate(matches):\n",
    "        start = match.start()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "        if prev_end < start:\n",
    "            sentences.append(text[prev_end:start].strip())\n",
    "        sentences.append(text[start:end].strip())\n",
    "        prev_end = end\n",
    "    \n",
    "    sentences = [s for s in sentences if s]\n",
    "    return sentences\n",
    "    \n",
    "class CustomSentenceSplitter(SentenceSplitter):\n",
    "    def _split_text(self, text: str, chunk_size: int) -> List[str]:\n",
    "        \"\"\"\n",
    "        Override to use custom sentence.\n",
    "        \"\"\"\n",
    "        return custom_sentence_splitter(text, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(isinstance(doc, Document) for doc in documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "\n",
    "# Limpieza\n",
    "for doc in documents:\n",
    "    doc.text = homogenizer(doc.text)\n",
    "    doc.text = eliminate_tildes(doc.text)\n",
    "    doc.text = clean_puntuation(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents[:20]:\n",
    "    print(\"The LLM see this: \\n\", doc.get_content(metadata_mode=MetadataMode.LLM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "end_cpu_usage, end_memory_usage = get_system_usage()\n",
    "\n",
    "# Calcular\n",
    "processing_time = end_time - start_time\n",
    "cpu_usage_diff = end_cpu_usage - start_cpu_usage\n",
    "memory_usage_dif = end_memory_usage - start_memory_usage\n",
    "\n",
    "print(f\"Tiempo de procedamiento: {processing_time:.2f} segundos\")\n",
    "print(f\"Incremento en el uso de CPU: {cpu_usage_diff:.2f}%\")\n",
    "print(f\"Incremento en el uso de memoria: {memory_usage_dif:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\", cache_folder = cache_folder)\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    with torch.no_grad():\n",
    "        embedding = embed_model(text.to(device))\n",
    "    return embedding.cpu().numpy()\n",
    "\n",
    "for doc in documents:\n",
    "    embedding = embed_model.get_text_embedding(doc.get_content())\n",
    "    doc.embedding = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents[:5]:\n",
    "    print(f\"Document: {doc.id_}, Emb: {doc.embedding[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "embeddings = [tuple(doc.embedding) for doc in document]\n",
    "\n",
    "embedding_counts = defaultdict(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "from llama_index.core.schema import IndexNode\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def build_nodes(documents):\n",
    "    nodes = []\n",
    "    splitter = CustomSentenceSplitter(chunking_tokenizer_fn=None)\n",
    "\n",
    "    for idx, doc in enumerate(tqdm(documents)):\n",
    "        cur_nodes = splitter.get_nodes_from_documents([doc])\n",
    "        for cur_node in cur_nodes:\n",
    "            # ID will be base + parent\n",
    "            file_name = doc.metadata[\"Numero exploracion\"]\n",
    "            new_node = IndexNode(\n",
    "                text=cur_node.text or \"None\",\n",
    "                index_id=str(file_name),\n",
    "                metadata=doc.metadata,\n",
    "            )\n",
    "            nodes.append(new_node)\n",
    "            \n",
    "    print(\"num nodes: \" + str(len(nodes)))\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = build_nodes(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_num_nodes = len(documents)\n",
    "actual_num_nodes = len(nodes)\n",
    "\n",
    "print(f\"Extected: {expected_num_nodes}\")\n",
    "print(f\"Actual: {actual_num_nodes}\")\n",
    "\n",
    "for node in nodes[:5]:\n",
    "    print(f\"Node ID: {node.index_id}, Metadata: {node.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_index(nodes, embed_model, out_path):\n",
    "    out_path = os.path.abspath(out_path)\n",
    "    #print(f\"Ruta {out_path}\")\n",
    "\n",
    "    #if not os.access(out_path, os.W_OK):\n",
    "        #print(\"No hay permiso\")\n",
    "        #return None\n",
    "    \n",
    "    if not os.path.exists(out_path):\n",
    "        index = VectorStoreIndex(nodes, embed_model=embed_model)\n",
    "        index.set_index_id(\"simple_index\")\n",
    "        index.storage_context.persist(f\"./{out_path}\")\n",
    "    else:\n",
    "        print(\"Directorio si existe\")\n",
    "        # rebuild storage context\n",
    "        storage_context = StorageContext.from_defaults(\n",
    "            persist_dir=out_path\n",
    "        )\n",
    "        # load index\n",
    "        index = load_index_from_storage(\n",
    "            storage_context, index_id=\"simple_index\", embed_model=embed_model\n",
    "        )\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar indice\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\", cache_folder = cache_folder)\n",
    "\n",
    "out_path = \"./chunck_index\"\n",
    "index = save_index(nodes, embed_model, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.indices.query.embedding_utils import get_top_k_embeddings\n",
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from typing import List, Any, Optional\n",
    "\n",
    "\n",
    "class HybridRetriever(BaseRetriever):\n",
    "    \"\"\"Hybrid retriever.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_index,\n",
    "        docstore,\n",
    "        similarity_top_k: int = 2,\n",
    "        out_top_k: Optional[int] = None,\n",
    "        alpha: float = 0.5,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self._vector_index = vector_index\n",
    "        self._embed_model = vector_index._embed_model\n",
    "        self._retriever = vector_index.as_retriever(\n",
    "            similarity_top_k=similarity_top_k\n",
    "        )\n",
    "        self._out_top_k = out_top_k or similarity_top_k\n",
    "        self._docstore = docstore\n",
    "        self._alpha = alpha\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "\n",
    "        # first retrieve chunks\n",
    "        nodes = self._retriever.retrieve(query_bundle.query_str)\n",
    "\n",
    "        # get documents, and embedding similiaryt between query and documents\n",
    "\n",
    "        ## get doc embeddings\n",
    "        docs = [self._docstore.get_document(n.node.index_id) for n in nodes]\n",
    "        doc_embeddings = [d.embedding for d in docs]\n",
    "        query_embedding = self._embed_model.get_query_embedding(\n",
    "            query_bundle.query_str\n",
    "        )\n",
    "\n",
    "        ## compute doc similarities\n",
    "        doc_similarities, doc_idxs = get_top_k_embeddings(\n",
    "            query_embedding, doc_embeddings\n",
    "        )\n",
    "\n",
    "        ## compute final similarity with doc similarities and original node similarity\n",
    "        result_tups = []\n",
    "        for doc_idx, doc_similarity in zip(doc_idxs, doc_similarities):\n",
    "            node = nodes[doc_idx]\n",
    "            # weight alpha * node similarity + (1-alpha) * doc similarity\n",
    "            full_similarity = (self._alpha * node.score) + (\n",
    "                (1 - self._alpha) * doc_similarity\n",
    "            )\n",
    "            full_similarity = round(full_similarity, 2)\n",
    "            print(\n",
    "                f\"Doc {doc_idx} (node score, doc similarity, full similarity): {(round(node.score, 2), round(doc_similarity, 2), full_similarity)}\"\n",
    "            )\n",
    "            result_tups.append((full_similarity, node))\n",
    "\n",
    "        result_tups = sorted(result_tups, key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # update scores\n",
    "        for full_score, node in result_tups:\n",
    "            node.score = full_score\n",
    "\n",
    "        return [n for _, n in result_tups][:out_top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "out_top_k = 3\n",
    "hybrid_retriever = HybridRetriever(\n",
    "    index, docstore, similarity_top_k=top_k, out_top_k=3, alpha=0.5\n",
    ")\n",
    "\n",
    "base_retriever = index.as_retriever(similarity_top_k=out_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_nodes(nodes, out_len: int = 5000):\n",
    "    for idx, n in enumerate(nodes):\n",
    "        lateralidad = n.metadata.get('Lateralidad mama')\n",
    "        bi_rads = n.metadata.get('BI-RADS')\n",
    "        print(f\"\\n\\n >> ID, Lateralidad: {lateralidad}, BI-RADS: {bi_rads}\")\n",
    "        print(n.get_content()[:out_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"Muestra numero de informes con birads 5 en la mama izquierda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = hybrid_retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "end_cpu_usage, end_memory_usage = get_system_usage()\n",
    "\n",
    "# Calcular\n",
    "processing_time = end_time - start_time\n",
    "cpu_usage_diff = end_cpu_usage - start_cpu_usage\n",
    "memory_usage_dif = end_memory_usage - start_memory_usage\n",
    "\n",
    "print(f\"Tiempo de procedamiento: {processing_time:.2f} segundos\")\n",
    "print(f\"Incremento en el uso de CPU: {cpu_usage_diff:.2f}%\")\n",
    "print(f\"Incremento en el uso de memoria: {memory_usage_dif:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# assemble query engine\n",
    "custom_query_engine = RetrieverQueryEngine(hybrid_retriever)\n",
    "base_query_engine = index.as_query_engine(similarity_top_k=out_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_str = custom_query_engine.query(query_str)\n",
    "print(str(response_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"Muestra numero de informes con birads 0 en la mama izquierda\",\n",
    "            \"Muestra numero de informes con birads 0 en la mama derecha\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"Muestra numero de informes con birads 1 en la mama izquierda\",\n",
    "            \"Muestra numero de informes con birads 1 en la mama derecha\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"Muestra numero de informes con birads 2 en la mama izquierda\",\n",
    "            \"Muestra numero de informes con birads 2 en la mama derecha\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"Muestra numero de informes con birads 3 en la mama izquierda\",\n",
    "            \"Muestra numero de informes con birads 3 en la mama derecha\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"Muestra numero de informes con birads 4 en la mama izquierda\",\n",
    "            \"Muestra numero de informes con birads 4 en la mama derecha\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"Muestra numero de informes con birads 4A en la mama izquierda\",\n",
    "            \"Muestra numero de informes con birads 4A en la mama derecha\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"Muestra numero de informes con birads 4B en la mama izquierda\",\n",
    "            \"Muestra numero de informes con birads 4B en la mama derecha\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"Muestra numero de informes con birads 4C en la mama izquierda\",\n",
    "            \"Muestra numero de informes con birads 4C en la mama derecha\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"Muestra numero de informes con birads 5 en la mama izquierda\",\n",
    "            \"Muestra numero de informes con birads 5 en la mama derecha\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"Muestra numero de informes con birads 6 en la mama izquierda\",\n",
    "            \"Muestra numero de informes con birads 6 en la mama derecha\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"¿Cuál es el birads para esta frase: lesiones benignas?\",\n",
    "            \"¿Cuál es el birads para esta frase: exploracion incompleta, exploracion insuficiente o valoracion adicional?\", \n",
    "            \"¿Cuál es el birads para esta frase: probablemente benignas?\",\n",
    "            \"¿Cuál es el birads para esta frase: alta sospecha de malignidad?\",\n",
    "            \"¿Cuál es el birads para esta frase: baja sospecha de malignidad?\",\n",
    "            \"¿Cuál es el birads para esta frase: moderada sospecha de malignidad?\",\n",
    "            \"¿Cuál es el birads para esta frase: altamente sospechosa de malignidad?\",\n",
    "            \"¿Cuál es el birads para esta frase: realización de biopsia, realización de marcaje o neoplasias?\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"¿Me podas decir cuáles son los tipos de mamas indicados en los informes?\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"¿Me podrías decir si hay informes escritos en lengua catalana?\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= [\"¿Me podrías decir si hay informes escritos en lengua catalana?\"]\n",
    "\n",
    "responses = {}\n",
    "\n",
    "for question_str in questions:\n",
    "    print(f\"Pregunta: {question_str}\")\n",
    "    response_str = custom_query_engine.query(question_str)\n",
    "    responses[question_str] = response_str\n",
    "    print(f\"Respuesta: {str(response_str)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes = base_retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nodes(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_str= \"¿Hay informes con birads 4C en la mama izquierda? ¿Cúal número de historia?\"\n",
    "response_str = custom_query_engine.query(question_str)\n",
    "print(str(response_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_str= \"¿Hay informes con birads 4B en la mama izquierda? ¿Cúal número de historia?\"\n",
    "response_str = custom_query_engine.query(question_str)\n",
    "print(str(response_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_str= \"¿Hay informes con birads 4B en la mama izquierda? ¿Cúal número de historia?\"\n",
    "response_str = custom_query_engine.query(question_str)\n",
    "print(str(response_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_str= \"¿Hay informes con birads 4C en la mama izquierda? ¿Cúal número de historia?\"\n",
    "response_str = custom_query_engine.query(question_str)\n",
    "print(str(response_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_4= \"Muestra 3 informes que tengan una categoría birads 4A y afecten la mama izquierda\"\n",
    "response_4 = custom_query_engine.query(question_4)\n",
    "print(str(response_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_base_4 = base_query_engine.query(question_4)\n",
    "print(str(response_base_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_5= \"¿Existen informes con birads 7 en la mama izquierda?\"\n",
    "response_5 = custom_query_engine.query(question_5)\n",
    "print(str(response_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_base_5 = base_query_engine.query(question_5)\n",
    "print(str(response_base_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_6= \"¿Existen informes con birads 4B me podas dar el número de exploracion?\"\n",
    "response_6 = custom_query_engine.query(question_6)\n",
    "print(str(response_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_7= \"Muestra 3 informes que tengan una categoría birads 4B\"\n",
    "response_7 = custom_query_engine.query(question_7)\n",
    "print(str(response_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"¿Qué informes tienen una clasificación BI-RADS 5 en la mama izquierda?\",\n",
    "    \"Muestra los informes clasificados como BI-RADS 4 en la mama derecha\",\n",
    "    \"¿Hay informes con BI-RADS 3 en la mama izquierda?\",\n",
    "    \"Muestra 3 informes que tengan una categoría BI-RADS 4A y afecten la mama izquierda\",\n",
    "    \"¿Existen informes con BI-RADS 7 en la mama izquierda?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in questions:\n",
    "    response_all = custom_query_engine.from_args(q)\n",
    "    print(\"Question -\", q, \"\\n\")\n",
    "    print(\"Response -\", response_all, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = hybrid_retriever.retrieve(questions[1])\n",
    "for c in contexts:\n",
    "    if \"birads\" in c.text:\n",
    "        print(\"\\nSí\\n\")\n",
    "    else:\n",
    "        print(\"\\nNo\\n\")\n",
    "\n",
    "print([c.text+\"*\"*100 for c in contexts])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "djcatalan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
